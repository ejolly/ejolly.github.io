---
title: "Test"
layout: post
date: 2016-01-01
tag: mturk
blog: false
description: test test 
---

# Imports and Function Defs


```python
import pandas as pd
import numpy as np
import seaborn as sns
from matplotlib import cm
import matplotlib.pyplot as plt
import re
from __future__ import division
import plotly 
import plotly.plotly as py
from scipy.stats import f_oneway
%matplotlib inline
plotly.offline.init_notebook_mode()
plt.style.use('seaborn-white')
sns.set_context('poster')
sns.set_palette("pastel")
pd.options.display.max_columns = 50
```



```python
#Top countries; cutoff = > 0.5%↔

```


![png](/blog/CoopPanel_files/CoopPanel_9_0.png)


## Forum Memberships


```python
#Forum membership↔

```


![png](/blog/CoopPanel_files/CoopPanel_11_0.png)



```python
#Multiple memberships↔

```


![png](/blog/CoopPanel_files/CoopPanel_12_0.png)



```python
#Aggregate other forum usage↔

```




    ['r/mturk',
     'i use the"hit grabber" but dont use forums',
     'turkopia',
     'p9r, princeton',
     'mturk.com',
     'mturk',
     'i search my answers on google search',
     'amazon mturk',
     'hits worth turking for',
     'turkopticion',
     'turkalert.com',
     'openturk',
     'hitgrabber which is now hitnotifier compiles a lot of the above postings so you know',
     'nan',
     'hitscraper',
     '0',
     'r/mturk/',
     'mturklist',
     'turkkit',
     'hitnotifier.com (aggregate)',
     'redit',
     'mturk artificial artificial intelligence',
     'cool money ideas',
     'mturk list',
     'http://hitnotifier.com/',
     'hit notifier (pulls top hits from different sources)',
     'turkopicon',
     'hit notifier',
     "survey's",
     'hitnotifier.com',
     'hitnotifier.com, which scrapes a few forums for me',
     'amazon mechanical turk',
     'http://www.mturklist.com/',
     'turk alert',
     'hit scraper',
     'i am doing hits by mturk.com',
     'private chats',
     'twitter',
     'hitgrabber tool which pulls from mturk grind and possibly others',
     'i use irc, we use irc the same way the forums are used.',
     'turkernation',
     'turkoptcon',
     '#mturk irc channel',
     'turkoptocon',
     'hitgrabber',
     'hitgrabber.net',
     'amazon',
     'none',
     'hitnotifier',
     'unu',
     'hit notifer',
     '/r/mturk',
     'i am using mturk only but the category is not shown in the above list.',
     'hitgrabber.net which is now hitnotifier.com',
     'mturk  website',
     'i have only used amazon mechanical turk']



## Forum Usage


```python
#Forum Usage↔

```

    *Percentages won't add to exactly 100 because some Workers responded incompletely



![png](/blog/CoopPanel_files/CoopPanel_15_1.png)



```python
#Forum Usage↔

```


![png](/blog/CoopPanel_files/CoopPanel_16_0.png)


# Target Sample Descriptives


```python
#Create a usable sample for seeding the app db and compute stats on it↔

```


```python
#Create treatment codes for each Worker with a baseline of incResp↔

```

## Worker Connection Distributions


```python
#Make Design table↔

```

    Excluded Workers = 287
    	Users who don't want to be contacted again = 157
    	Users with incomplete responses (ambiguous classification) = 94
    	Users who put uninterpretable responses to all questions (no classification) = 6
    	Users who claimed they did not use a forum but provided a value for Visits = 30
    	Users who claimed they did not use a forum but provided a value for Posts = 0
    
                            Don't Know Personally  Know Personally
    No Visits and No Posts                   1515              667
    Visits and No Posts                      1956              995
    Vists and Posts                           671             1559



![png](/blog/CoopPanel_files/CoopPanel_21_1.png)


## Treatable Groups Based on Forum Usage

Here I've split all of the Workers into 3 "treatable" types from the several above:
1. Workers who **Post** on forums but don't know anyone personally
2. Workers who **Know** people personally but don't use forums
3. Workers who both **Post** on forums and **Know** people personally

I've specifically left out other types of workers because we need Workers to be shared **with**:
1. Workers who **Visit** forums but don't post or don't know anyone personally
2. Workers who **Visit** forums but don't post and do **Know** people personally\*   
3. Workers who don't know, don't visit, and don't post

\*We could revisit this one, e.g. consider combining this group with Workers who **Know** people personally and **Post**


```python
#Forum behavior↔

```

    Post but don't know 671
    Know but don't post 667
    Post and Know 1559
    



![png](/blog/CoopPanel_files/CoopPanel_24_1.png)



```python
#Actually create the bins above
users['knownBin'] = 'nan'
users['postBin'] = 'nan'

#Post only
users.ix[users.connCode == 'visit_post_noknown', 'postBin'] = (
    pd.cut(users.ix[users.connCode == 'visit_post_noknown','forumPosts'],bins,labels=labels)
)
#Known only
users.ix[users.connCode == 'novisit_nopost_known', 'knownBin'] = (
          pd.cut(users.ix[users.connCode == 'novisit_nopost_known','numKnown'],bins,labels=labels)
)
#Post and Known
users.ix[users.connCode == 'visit_post_known', 'knownBin'] = (
          pd.cut(users.ix[users.connCode == 'visit_post_known','numKnown'],bins,labels=labels)
)
users.ix[users.connCode == 'visit_post_known', 'postBin'] = (
          pd.cut(users.ix[users.connCode == 'visit_post_known','forumPosts'],bins,labels=labels)
)
#Define some helper functions 
def filterByBin(users,binsToChoose):↔

def filterByVal(users,lower,upper):↔

```

## Filter treatable Workers by Forum Posts and Number Known


```python
db = filterByVal(users, 1,6)
print "Workers remainig after filtering applied: %d" % db.shape[0]
```

    Workers remainig after filtering applied: 1957


**Few examples of how many Workers we retain based on cut-off criteria**


```python
#Sub group sampling
binsToChoose = ['1','2-3','4-6']
db = filterByBin(users, binsToChoose)

ax = (db[(db.postBin != '1') & (db.knownBin != '1')].groupby('connCode')['WorkerId'].count()
      .plot(kind = 'bar', position = 0, width=.1,label='Range = 2-6',color=sns.color_palette()[2]));
(db[(db.postBin != '4-6') & (db.knownBin != '4-6')].groupby('connCode')['WorkerId'].count()
 .plot(kind='bar',position=1, ax = ax,width=.1, color=sns.color_palette()[3],rot=0,label='Range = 1-3'));
(db.groupby('connCode')['WorkerId'].count()
 .plot(kind='bar',position=2, ax = ax,width=.1, color=sns.color_palette()[4],rot=0,label='Range = 1-6'));

ax.set_xlabel('');
ax.set_xticklabels(['Know Only','Know and Post','Post Only']);
ax.set_ylabel('Number of Workers');
ax.legend();
plt.title('Number of Treatable Workers by Cutoff (Max = ' + str(db.shape[0]) + ')');
```


![png](/blog/CoopPanel_files/CoopPanel_29_0.png)


## Treatment Group Creation

**Here we create the actual treatment groups. Because we want each group to have an equal number of Workers of each type, we have to limit the number of workers of each type, in each treatment to size of smallest group of Workers**


```python
def assignTreatment(workerTypes, treatments):↔

def matchTreatmentGroups(loadFile, fileName='', groupbyDF=[],iters=100,threshold=0.9):
    """
    Function to find best split of groups such that the ratio of between to within group variance is 
    minimized. Like propensity matching but with an ANOVA. Depends on assignTreatment function.
    Iters = max number of random split iterations to try
    threshold = min p-val threshold for ANOVA across treatments
    
    """
    count, pP, pN = 0,0,0
    if loadFile:
        t = pd.read_csv(fileName)
    else:
        #Iterate through different random splits until an ANOVA fails to see a difference, i.e.
        #minimize the ratio of between to within group variance
        while (pP <= threshold or pN <= threshold) and count < iters:
            t = assignTreatment(groupbyDF,treatments)
            _, pP = f_oneway(*[group[1]['forumPosts'].values for group in t.groupby('treatment')])
            _, pN = f_oneway(*[group[1]['numKnown'].values for group in t.groupby('treatment')])
            count += 1
    
    print 'Final:\n'
    print "One-way ANOVA on Forum Posts across treatments: "
    print f_oneway(*[group[1]['forumPosts'].values for group in t.groupby('treatment')]) 
    print "\nOne-way ANOVA on Number Known across treatments: "
    print f_oneway(*[group[1]['numKnown'].values for group in t.groupby('treatment')]) 
    if not loadFile:
        print "\nIteration = " + str(count)
    print "\nTotal treated Workers: %d" % t.shape[0]
    print "\nNumber of Workers in each treatment: %d" % t.groupby('treatment')['WorkerId'].count()[0]
    print "\nNumber of Workers of each type in each treatment: %d" % t.groupby('treatment')['connCode'].value_counts()[0]

    groupedD = t.groupby('treatment')[['forumPosts','numKnown']].agg({
        'Mean':'mean',
        'Sem':'sem'
    })
    ax = groupedD.plot(y='Mean',kind = 'bar',rot = 0,yerr='Sem');
    ax.set_xlabel('Treatments',fontsize=20);
    ax.set_ylabel('Average',fontsize=20);
    ax.legend(loc='upper right');
    #Some plotting properties
    yUp = groupedD['Mean'].max().max() + groupedD['Sem'].max().max() + 1
    ax.set_ylim(1,yUp);
    if count == iters:
        print "\n FAILED TO FIND ADEQUATE TREATMENT SPLITS!"
    if t.shape[0] < 50:
        print "\n WARNING SMALL SAMPLE SIZE, MATCHING UNRELIABLE!"
    if not loadFile:
        return t

treatments = [
    'control',
    'costly',
    'framing',
    'reciprocity',
    'reputation'
    ]
lowerCutOff = 1
upperCutOff = 6
db = filterByVal(users,lowerCutOff,upperCutOff)
workerTypes = db.groupby('connCode')
t=matchTreatmentGroups(True,'matchedTreatments.csv')
#t.to_csv('matchedTreatments.csv',index=False)
```

    Final:
    
    One-way ANOVA on Forum Posts across treatments: 
    F_onewayResult(statistic=0.16405879046210442, pvalue=0.95658175908541265)
    
    One-way ANOVA on Number Known across treatments: 
    F_onewayResult(statistic=0.15833148194943067, pvalue=0.95925820570561771)
    
    Total treated Workers: 1605
    
    Number of Workers in each treatment: 321
    
    Number of Workers of each type in each treatment: 107



![png](/blog/CoopPanel_files/CoopPanel_32_1.png)



```python
groupedD = t.groupby(['treatment','connCode'])[['forumPosts','numKnown']].agg({
        'Mean':'mean',
        'Sem':'sem'
    }).stack().reset_index().rename(columns={'level_2':'shareType'})
ax = sns.factorplot(data=groupedD,x='shareType',y='Mean',hue='connCode',col='treatment',kind='bar')
ax.set_xlabels('');
```


![png](/blog/CoopPanel_files/CoopPanel_33_0.png)


## Database Creation


```python
t = pd.read_csv('matchedTreatments.csv')
t.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>WorkerId</th>
      <th>age</th>
      <th>country</th>
      <th>gender</th>
      <th>forumVisits</th>
      <th>forumPosts</th>
      <th>numKnown</th>
      <th>noForum</th>
      <th>connCode</th>
      <th>knownBin</th>
      <th>postBin</th>
      <th>treatment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A1YN90JJ8W9WRH</td>
      <td>{}</td>
      <td>USA</td>
      <td>female</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1</td>
      <td>novisit_nopost_known</td>
      <td>1</td>
      <td>NaN</td>
      <td>control</td>
    </tr>
    <tr>
      <th>1</th>
      <td>A38PVRBHXSCQD1</td>
      <td>39</td>
      <td>IND</td>
      <td>male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1</td>
      <td>novisit_nopost_known</td>
      <td>1</td>
      <td>NaN</td>
      <td>control</td>
    </tr>
    <tr>
      <th>2</th>
      <td>A1PIJKC3FM7B60</td>
      <td>54</td>
      <td>USA</td>
      <td>female</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1</td>
      <td>novisit_nopost_known</td>
      <td>1</td>
      <td>NaN</td>
      <td>control</td>
    </tr>
    <tr>
      <th>3</th>
      <td>A31RNXD16AHHGX</td>
      <td>23</td>
      <td>USA</td>
      <td>female</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1</td>
      <td>novisit_nopost_known</td>
      <td>1</td>
      <td>NaN</td>
      <td>control</td>
    </tr>
    <tr>
      <th>4</th>
      <td>A2820MTKM9SCC8</td>
      <td>19</td>
      <td>USA</td>
      <td>male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>1</td>
      <td>novisit_nopost_known</td>
      <td>2-3</td>
      <td>NaN</td>
      <td>control</td>
    </tr>
  </tbody>
</table>
</div>




```python
#Make Workers DB
Workers = t.copy().drop(['noForum','knownBin','postBin'],axis=1).rename(columns = {
        'connCode':'workerType','treatment':'Treatment'})
#Randomly shuffle rows
Workers = Workers.sample(frac=1).reset_index(drop=True) 
#Workers.to_csv('db/Workers.csv',index=False)
Workers.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>WorkerId</th>
      <th>age</th>
      <th>country</th>
      <th>gender</th>
      <th>forumVisits</th>
      <th>forumPosts</th>
      <th>numKnown</th>
      <th>workerType</th>
      <th>Treatment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A1YN90JJ8W9WRH</td>
      <td>{}</td>
      <td>USA</td>
      <td>female</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>novisit_nopost_known</td>
      <td>control</td>
    </tr>
    <tr>
      <th>1</th>
      <td>A38PVRBHXSCQD1</td>
      <td>39</td>
      <td>IND</td>
      <td>male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>novisit_nopost_known</td>
      <td>control</td>
    </tr>
    <tr>
      <th>2</th>
      <td>A1PIJKC3FM7B60</td>
      <td>54</td>
      <td>USA</td>
      <td>female</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>novisit_nopost_known</td>
      <td>control</td>
    </tr>
    <tr>
      <th>3</th>
      <td>A31RNXD16AHHGX</td>
      <td>23</td>
      <td>USA</td>
      <td>female</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>novisit_nopost_known</td>
      <td>control</td>
    </tr>
    <tr>
      <th>4</th>
      <td>A2820MTKM9SCC8</td>
      <td>19</td>
      <td>USA</td>
      <td>male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>novisit_nopost_known</td>
      <td>control</td>
    </tr>
  </tbody>
</table>
</div>




```python
Workers = pd.read_csv('db/Workers.csv')
Workers.shape[0] == len(Workers.WorkerId.unique())
```




    True




```python
#For updated treatment types
Workers['Treatment'].apply(lambda x: 'costless' if x == 'control' else 'leverage' if x == 'framing' else x)
Workers = Workers.sample(frac=1).reset_index(drop=True)
```


```python
np.round(800/3)
```




    267.0




```python
#For the new run (to launch on Sep 6) randomly sample from each kind of worker type such that at least 1/3rd are of each of the 3 types; treatments are now ignored at assigned at run time
WorkersPerType = int(np.round(800/len(Workers.workerType.unique()))) #267
replace = False  # without replacement

WorkersNew = Workers.groupby('workerType').apply(lambda group: group.loc[np.random.choice(group.index,WorkersPerType,False)]).drop('Treatment',axis=1).reset_index(drop=True)
WorkersNew = WorkersNew.iloc[:WorkersNew.shape[0]-1]
assert WorkersNew.shape[0] == 800
WorkersNew.to_csv('db/WorkersNew.csv',index=False)
```


```python
Workers = pd.read_csv('db/WorkersNew.csv')
```


```python

```


```python
Workers = pd.read_csv('db/WorkersNew.csv')
Workers = Workers.drop('Unnamed: 0',axis=1)
Workers = Workers.sample(frac=1).reset_index(drop=True) 
Workers.to_csv('db/WorkersNew.csv',index=False)
```


```python
workersPerTreatment = pd.read_csv('db/Workers.csv').groupby("Treatment")['WorkerId'].count()[0] #321
numTreatment = len(t.treatment.unique()) #5
reward = {'Amount': 0.10, 'CurrencyCode': 'USD','FormattedPrice':'$0.10'}
description = 'This HIT involves answering questions about tweets.'
hitsPerWorker = 100
titles = ['Labeling Tweets','Categorizing Tweets','Classifying Tweets','Describing Tweets','Characterizing Tweets']
info = 'This HIT involves answering questions about tweets. An access code is required.'
keywords = 'tweet, label, tag, questions'

HITs = (pd.DataFrame({
            'Treatment': np.hstack([np.repeat(treatment,workersPerTreatment*hitsPerWorker) for treatment in t.treatment.unique()]),
            'Title': np.hstack([np.repeat(title,workersPerTreatment*hitsPerWorker) for title in titles]),
            'MaxAssignments': np.hstack([np.repeat(2,workersPerTreatment*hitsPerWorker), 
                                         np.repeat(1,workersPerTreatment*hitsPerWorker*(numTreatment-1))]),
            'Reward': np.repeat(reward, workersPerTreatment*numTreatment*hitsPerWorker),
            'Description': np.repeat(description, workersPerTreatment*numTreatment*hitsPerWorker),
            'Keywords': np.repeat(keywords,workersPerTreatment*numTreatment*hitsPerWorker)           
        }))
HITs.to_csv('db/HITs.csv',index=False)
HITs.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Description</th>
      <th>Keywords</th>
      <th>MaxAssignments</th>
      <th>Reward</th>
      <th>Title</th>
      <th>Treatment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>This HIT involves answering questions about tw...</td>
      <td>tweet, label, tag, questions</td>
      <td>2</td>
      <td>{u'Amount': 0.1, u'CurrencyCode': u'USD', u'Fo...</td>
      <td>Labeling Tweets</td>
      <td>control</td>
    </tr>
    <tr>
      <th>1</th>
      <td>This HIT involves answering questions about tw...</td>
      <td>tweet, label, tag, questions</td>
      <td>2</td>
      <td>{u'Amount': 0.1, u'CurrencyCode': u'USD', u'Fo...</td>
      <td>Labeling Tweets</td>
      <td>control</td>
    </tr>
    <tr>
      <th>2</th>
      <td>This HIT involves answering questions about tw...</td>
      <td>tweet, label, tag, questions</td>
      <td>2</td>
      <td>{u'Amount': 0.1, u'CurrencyCode': u'USD', u'Fo...</td>
      <td>Labeling Tweets</td>
      <td>control</td>
    </tr>
    <tr>
      <th>3</th>
      <td>This HIT involves answering questions about tw...</td>
      <td>tweet, label, tag, questions</td>
      <td>2</td>
      <td>{u'Amount': 0.1, u'CurrencyCode': u'USD', u'Fo...</td>
      <td>Labeling Tweets</td>
      <td>control</td>
    </tr>
    <tr>
      <th>4</th>
      <td>This HIT involves answering questions about tw...</td>
      <td>tweet, label, tag, questions</td>
      <td>2</td>
      <td>{u'Amount': 0.1, u'CurrencyCode': u'USD', u'Fo...</td>
      <td>Labeling Tweets</td>
      <td>control</td>
    </tr>
  </tbody>
</table>
</div>



### Generate Submit Datetimes for Survey HITs


```python
#Look up submit times
Workers = Workers.sort_values('WorkerId').reset_index(drop=True)
Workers['AcceptTime'] = (
    pd.to_datetime(allData[allData.WorkerId.isin(Workers.WorkerId)].sort_values('WorkerId').ix[:,'AcceptTime'].values))
Workers = Workers.set_index('AcceptTime').drop('AcceptTime').sort_index()
Workers.head()

ax = Workers.groupby(pd.TimeGrouper(freq='90min'))['WorkerId'].count().plot(kind='bar',figsize=(14,6));
binDates = [label.get_text() for label in ax.xaxis.get_ticklabels()]
ax.set_xticklabels('');
ax.xaxis.set_ticks_position('bottom');
ax.xaxis.set_tick_params(width=2,length=-10,which='major');
ax.set_title('HIT Accept Time After Posting',fontsize=24);
ax.xaxis.label.set_fontsize(22);
ax.set_ylabel('Number of Workers',fontsize=22);
ax.set_xlabel('90 minute increments',fontsize=22);
```


![png](/blog/CoopPanel_files/CoopPanel_46_0.png)



```python
fig, ax = plt.subplots(1,1)
ax.hist(Workers.index.hour,bins=24);
ax.set_xlabel('Hour of day in 24hr time');
ax.set_xlim(0,23);
ax.set_ylabel('Number of Workers');
ax.set_xticks(range(24));
plt.title('Accept Times During Each Day');

```


![png](/blog/CoopPanel_files/CoopPanel_47_0.png)



```python
tGroups = Workers.groupby('Treatment')
fig, ax = plt.subplots(1,1,figsize=(20,10))
for label, group in tGroups:
    ax.hist(group.index.hour, bins=24, label=label, alpha = .5)
plt.legend()        
```




    <matplotlib.legend.Legend at 0x129661250>




![png](CoopPanel_files/CoopPanel_48_1.png)



```python
tGroups = Workers.groupby('Treatment')
fig, axs = plt.subplots(5,1,figsize=(20,20))
idx = 0
for label, group in tGroups:
    axs[idx].hist(group.index.hour, bins=24, alpha = .5)
    idx +=1
        
    
```


![png](CoopPanel_files/CoopPanel_49_0.png)


# HIT Data


```python
Y = (pd.read_csv('Yolanda.csv',encoding='ISO-8859-1')
     .drop(['Unnamed: 8','Image-link'],axis=1)
     .iloc[0::2,:]
     .reset_index(drop=True)
     .rename(columns = {'User-Name':'User','Time-stamp':'Datetime','TweetID':'tweetID'})
     )
Y['Date'] = Y['Datetime'].apply(lambda x: x[:8])
Y['Time'] = Y['Datetime'].apply(lambda x: x[9:])
Y['Storm'] = 'Yolanda'
Y = Y.drop(Y.index[1379]).reset_index(drop=True)
Y.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>User</th>
      <th>Tweet</th>
      <th>Datetime</th>
      <th>Location</th>
      <th>Latitude</th>
      <th>Longitude</th>
      <th>tweetID</th>
      <th>Date</th>
      <th>Time</th>
      <th>Storm</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>TheEdwardBelaro</td>
      <td>Pati China magbibigay ng $100,000 sa Pilipinas...</td>
      <td>11/12/13 8:09</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.001730e+17</td>
      <td>11/12/13</td>
      <td>8:09</td>
      <td>Yolanda</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ShutangInaBeks</td>
      <td>Yung eksenang challenge para sa atin ang mga n...</td>
      <td>11/12/13 8:09</td>
      <td>NaN</td>
      <td>12.8797</td>
      <td>121.774000</td>
      <td>4.001730e+17</td>
      <td>11/12/13</td>
      <td>8:09</td>
      <td>Yolanda</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ViolinoChang</td>
      <td>Kahit maliit basta makakatulog. Sa kahit na an...</td>
      <td>11/12/13 8:09</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.001730e+17</td>
      <td>11/12/13</td>
      <td>8:09</td>
      <td>Yolanda</td>
    </tr>
    <tr>
      <th>3</th>
      <td>LOrientLeJour</td>
      <td>DIAPO Aprs le passage de #Haiyan : images de ...</td>
      <td>11/12/13 8:09</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.001730e+17</td>
      <td>11/12/13</td>
      <td>8:09</td>
      <td>Yolanda</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Rachaelorrsome</td>
      <td>10,000 feared dead in #Haiyan UK Govt and NGOs...</td>
      <td>11/12/13 8:09</td>
      <td>NaN</td>
      <td>51.5002</td>
      <td>-0.126236</td>
      <td>4.001730e+17</td>
      <td>11/12/13</td>
      <td>8:09</td>
      <td>Yolanda</td>
    </tr>
  </tbody>
</table>
</div>




```python
P = (pd.read_csv('Pablo.csv',encoding='ISO-8859-1')
     .rename(columns = {'text':'Tweet','date':'Datetime','username':'User','tweetid':'tweetID'})
     )
P['Datetime'] = pd.to_datetime(P.Datetime).apply(lambda x: str(x.strftime('%m/%d/%y %I:%M')))
P['Date'] = P['Datetime'].apply(lambda x: x[:8])
P['Time'] = P['Datetime'].apply(lambda x: x[9:] if x[9] != '0' else x[10:])
P['Storm'] = 'Pablo'
P.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>tweetID</th>
      <th>Tweet</th>
      <th>Datetime</th>
      <th>User</th>
      <th>userid</th>
      <th>Date</th>
      <th>Time</th>
      <th>Storm</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2.760000e+17</td>
      <td>The Spongebob approach to flood control http:...</td>
      <td>12/05/12 12:00</td>
      <td>ShaiPanela</td>
      <td>16416943</td>
      <td>12/05/12</td>
      <td>12:00</td>
      <td>Pablo</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.760000e+17</td>
      <td>Do you people still remember this?Well I can'...</td>
      <td>12/05/12 12:03</td>
      <td>ToFFyMENcHaveZ</td>
      <td>155115393</td>
      <td>12/05/12</td>
      <td>12:03</td>
      <td>Pablo</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2.760000e+17</td>
      <td>@dost_pagasa: At 02:00AM 5/DEC/2012 the eye ...</td>
      <td>12/05/12 12:04</td>
      <td>whoaitsnadine</td>
      <td>26439938</td>
      <td>12/05/12</td>
      <td>12:04</td>
      <td>Pablo</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2.760000e+17</td>
      <td>Death toll mounts in wake of #PabloPH http://...</td>
      <td>12/05/12 12:05</td>
      <td>gmanews</td>
      <td>39453212</td>
      <td>12/05/12</td>
      <td>12:05</td>
      <td>Pablo</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.760000e+17</td>
      <td>Are Filipinos ready to face #PabloPH (interna...</td>
      <td>12/05/12 12:05</td>
      <td>RanterXRanter</td>
      <td>364718481</td>
      <td>12/05/12</td>
      <td>12:05</td>
      <td>Pablo</td>
    </tr>
  </tbody>
</table>
</div>




```python
Content = Y.append(P,ignore_index=True)
Content['HITCount'] = 0
Content = Content[[
        'User','Tweet','Date','Time','HITCount','Storm','Datetime','userid','tweetID','Location','Latitude','Longitude']]
Content.head()
#Content.to_csv('db/Content.csv',encoding='utf-8',index=False)
```


```python
Content.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>User</th>
      <th>Tweet</th>
      <th>Date</th>
      <th>Time</th>
      <th>Storm</th>
      <th>Datetime</th>
      <th>userid</th>
      <th>tweetID</th>
      <th>Location</th>
      <th>Latitude</th>
      <th>Longitude</th>
      <th>Count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>TheEdwardBelaro</td>
      <td>Pati China magbibigay ng $100,000 sa Pilipinas...</td>
      <td>11/12/13</td>
      <td>8:09</td>
      <td>Yolanda</td>
      <td>11/12/13 8:09</td>
      <td>NaN</td>
      <td>4.001730e+17</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ShutangInaBeks</td>
      <td>Yung eksenang challenge para sa atin ang mga n...</td>
      <td>11/12/13</td>
      <td>8:09</td>
      <td>Yolanda</td>
      <td>11/12/13 8:09</td>
      <td>NaN</td>
      <td>4.001730e+17</td>
      <td>NaN</td>
      <td>12.8797</td>
      <td>121.774000</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ViolinoChang</td>
      <td>Kahit maliit basta makakatulog. Sa kahit na an...</td>
      <td>11/12/13</td>
      <td>8:09</td>
      <td>Yolanda</td>
      <td>11/12/13 8:09</td>
      <td>NaN</td>
      <td>4.001730e+17</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>LOrientLeJour</td>
      <td>DIAPO Aprs le passage de #Haiyan : images de ...</td>
      <td>11/12/13</td>
      <td>8:09</td>
      <td>Yolanda</td>
      <td>11/12/13 8:09</td>
      <td>NaN</td>
      <td>4.001730e+17</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Rachaelorrsome</td>
      <td>10,000 feared dead in #Haiyan UK Govt and NGOs...</td>
      <td>11/12/13</td>
      <td>8:09</td>
      <td>Yolanda</td>
      <td>11/12/13 8:09</td>
      <td>NaN</td>
      <td>4.001730e+17</td>
      <td>NaN</td>
      <td>51.5002</td>
      <td>-0.126236</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
Content = pd.read_csv('db/Content.csv')
Content.shape[0] == len(Content.User.unique())
```




    False




```python
 pd.DataFrame({
        'Percentage of HITs Shared': np.array([10,5,15,16,30,9,4,15,30,16,11,6,14,32,32]),
        'Treatment':np.repeat(['Baseline','Costly','Framing','Reciprocity','Reputation'],3),
        'Worker Type': np.array([np.repeat('Forums, No Personal Relationships',5),np.repeat('No Forums, Personal Relationships',5),np.repeat('Forums,Personal Relationship',5)]).flatten()

    })
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Percentage of HITs Shared</th>
      <th>Treatment</th>
      <th>Worker Type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10</td>
      <td>Baseline</td>
      <td>Forums, No Personal Relationships</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5</td>
      <td>Baseline</td>
      <td>Forums, No Personal Relationships</td>
    </tr>
    <tr>
      <th>2</th>
      <td>15</td>
      <td>Baseline</td>
      <td>Forums, No Personal Relationships</td>
    </tr>
    <tr>
      <th>3</th>
      <td>16</td>
      <td>Costly</td>
      <td>Forums, No Personal Relationships</td>
    </tr>
    <tr>
      <th>4</th>
      <td>30</td>
      <td>Costly</td>
      <td>Forums, No Personal Relationships</td>
    </tr>
    <tr>
      <th>5</th>
      <td>9</td>
      <td>Costly</td>
      <td>No Forums, Personal Relationships</td>
    </tr>
    <tr>
      <th>6</th>
      <td>4</td>
      <td>Framing</td>
      <td>No Forums, Personal Relationships</td>
    </tr>
    <tr>
      <th>7</th>
      <td>15</td>
      <td>Framing</td>
      <td>No Forums, Personal Relationships</td>
    </tr>
    <tr>
      <th>8</th>
      <td>30</td>
      <td>Framing</td>
      <td>No Forums, Personal Relationships</td>
    </tr>
    <tr>
      <th>9</th>
      <td>16</td>
      <td>Reciprocity</td>
      <td>No Forums, Personal Relationships</td>
    </tr>
    <tr>
      <th>10</th>
      <td>11</td>
      <td>Reciprocity</td>
      <td>Forums,Personal Relationship</td>
    </tr>
    <tr>
      <th>11</th>
      <td>6</td>
      <td>Reciprocity</td>
      <td>Forums,Personal Relationship</td>
    </tr>
    <tr>
      <th>12</th>
      <td>14</td>
      <td>Reputation</td>
      <td>Forums,Personal Relationship</td>
    </tr>
    <tr>
      <th>13</th>
      <td>32</td>
      <td>Reputation</td>
      <td>Forums,Personal Relationship</td>
    </tr>
    <tr>
      <th>14</th>
      <td>32</td>
      <td>Reputation</td>
      <td>Forums,Personal Relationship</td>
    </tr>
  </tbody>
</table>
</div>




```python
d
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Percentage of HITs Shared</th>
      <th>Treatment</th>
      <th>Worker Type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10</td>
      <td>Baseline</td>
      <td>Forums, No Personal Relationships</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5</td>
      <td>Baseline</td>
      <td>Forums, No Personal Relationships</td>
    </tr>
    <tr>
      <th>2</th>
      <td>15</td>
      <td>Baseline</td>
      <td>Forums, No Personal Relationships</td>
    </tr>
    <tr>
      <th>3</th>
      <td>16</td>
      <td>Costly</td>
      <td>Forums, No Personal Relationships</td>
    </tr>
    <tr>
      <th>4</th>
      <td>30</td>
      <td>Costly</td>
      <td>Forums, No Personal Relationships</td>
    </tr>
    <tr>
      <th>5</th>
      <td>9</td>
      <td>Costly</td>
      <td>No Forums, Personal Relationships</td>
    </tr>
    <tr>
      <th>6</th>
      <td>4</td>
      <td>Framing</td>
      <td>No Forums, Personal Relationships</td>
    </tr>
    <tr>
      <th>7</th>
      <td>15</td>
      <td>Framing</td>
      <td>No Forums, Personal Relationships</td>
    </tr>
    <tr>
      <th>8</th>
      <td>30</td>
      <td>Framing</td>
      <td>No Forums, Personal Relationships</td>
    </tr>
    <tr>
      <th>9</th>
      <td>16</td>
      <td>Reciprocity</td>
      <td>No Forums, Personal Relationships</td>
    </tr>
    <tr>
      <th>10</th>
      <td>11</td>
      <td>Reciprocity</td>
      <td>Forums,Personal Relationship</td>
    </tr>
    <tr>
      <th>11</th>
      <td>6</td>
      <td>Reciprocity</td>
      <td>Forums,Personal Relationship</td>
    </tr>
    <tr>
      <th>12</th>
      <td>14</td>
      <td>Reputation</td>
      <td>Forums,Personal Relationship</td>
    </tr>
    <tr>
      <th>13</th>
      <td>32</td>
      <td>Reputation</td>
      <td>Forums,Personal Relationship</td>
    </tr>
    <tr>
      <th>14</th>
      <td>32</td>
      <td>Reputation</td>
      <td>Forums,Personal Relationship</td>
    </tr>
  </tbody>
</table>
</div>



# Hypothesized Results


```python
fig, ax = plt.subplots(1,1,figsize=(12,8));
d =  pd.DataFrame({
        'Percentage of HITs Shared': np.array([70,5,15,16,30,40,4,15,30,16,80,6,14,32,32]),
        'Treatment':np.repeat(['Baseline','Costly','Framing','Reciprocity','Reputation'],3),
        'Worker Type': np.array([np.repeat('Forum Users, No Personal Relationships',5),np.repeat("Not Forum Users, Have Personal Relationships",5),np.repeat('Forum Users, Have Personal Relationships',5)]).flatten()

    })
for label, group in d.groupby('Worker Type'):
    group.plot(kind="line",x='Treatment',y='Percentage of HITs Shared', ax=ax, label=label)


#.plot(kind='line',x='Treatment',y='Percentage of HITs Shared',label = 'Worker Type',legend=True)
#ax = sns.pointplot(x='Treatment',y='Percentage of HITs Shared',hue='Worker Type',data=d) 
ax.set_ylabel('Percentage of HITs Shared',fontsize=20);
ax.set_ylim(0,100);
plt.xticks([0,1,2,3,4],d.Treatment.unique())
ax.tick_params(axis='x', labelsize=20);
ax.tick_params(axis='y', labelsize=20);
ax.set_xlabel('');
plt.plot([0,4], [20,20], color='grey', linestyle='--', linewidth=2);
plt.text(.25,21,'Typical Contribution Level in Dictator Game',fontsize=20,color='slategrey');
plt.legend(title='Types of Workers',fontsize=16);
```


![png](/blog/CoopPanel_files/CoopPanel_59_0.png)


	
```python
#Log post plots (suppressed)↔

```


```python
#Corr plots (suppressed)↔

```
